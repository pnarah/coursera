{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ead85ee",
   "metadata": {},
   "source": [
    "# Time travel\n",
    "In a typical chatbot workflow, the user interacts with the bot one or more times to accomplish a task. Memory and a human-in-the-loop enable checkpoints in the graph state and control future responses.\n",
    "\n",
    "What if you want a user to be able to start from a previous response and explore a different outcome? Or what if you want users to be able to rewind your chatbot's work to fix mistakes or try a different strategy, something that is common in applications like autonomous software engineers?\n",
    "\n",
    "You can create these types of experiences using LangGraph's built-in time travel functionality.\n",
    "\n",
    "https://langchain-ai.github.io/langgraph/tutorials/get-started/6-time-travel/#time-travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702f7f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U \"langchain[openai]\" --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10918f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"openai:gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edbcf67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ce937b",
   "metadata": {},
   "source": [
    "# 2. Add steps¶\n",
    "Add steps to your graph. Every step will be checkpointed in its state history:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765f04be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (call_9Xzg0GXBuG5uLlVIBA3A66qZ)\n",
      " Call ID: call_9Xzg0GXBuG5uLlVIBA3A66qZ\n",
      "  Args:\n",
      "    query: LangGraph\n",
      "    search_depth: advanced\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"url\": \"https://www.ibm.com/think/topics/langgraph\", \"title\": \"What is LangGraph? - IBM\", \"content\": \"LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] Agent systems: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\n\\nLLM applications: By using LangGraph’s capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.\", \"score\": 0.9353998, \"raw_content\": null}, {\"title\": \"What is LangGraph? - GeeksforGeeks\", \"url\": \"https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/\", \"content\": \"LangGraph is a Python library that helps you build applications like chatbots or AI agents by organizing their logic step-by-step using state machine model. This means you can define how the application should behave at each step such as classifying input, generating a response or calling a tool and the application remembers its progress by storing information in a shared state.\", \"score\": 0.9301101, \"raw_content\": null}], \"response_time\": 2.17}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph is an open-source AI agent framework designed to build, deploy, and manage complex generative AI workflows. Created by LangChain, it uses graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. This allows for scalable and efficient management of large language models (LLMs) and their applications.\n",
      "\n",
      "Key points about LangGraph include:\n",
      "- It provides a set of tools and libraries for creating, running, and optimizing LLMs.\n",
      "- It enables building agent-based systems applicable in robotics, autonomous vehicles, video games, and personalized AI solutions.\n",
      "- LangGraph enhances decision-making by modeling complex relationships between nodes and using AI agents to analyze past actions and feedback, a process known as reflection.\n",
      "- It allows AI workflows to scale without losing efficiency.\n",
      "\n",
      "Additionally, LangGraph is also described as a Python library that organizes application logic step-by-step using a state machine model. This helps in building applications like chatbots or AI agents by defining behavior at each step and remembering progress via shared state storage.\n",
      "\n",
      "If you want more detailed info or specific examples of LangGraph in use, let me know!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"I'm learning LangGraph. \"\n",
    "                    \"Could you do some research on it for me?\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adad0eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Ya that's helpful. Maybe I'll build an autonomous agent with it!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like an exciting project! LangGraph's graph-based framework and state machine model make it well-suited for building autonomous agents that can handle complex workflows and decision-making processes. If you need any help with getting started, designing your agent, or troubleshooting along the way, feel free to ask. Good luck with your autonomous agent build!\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": (\n",
    "                    \"Ya that's helpful. Maybe I'll \"\n",
    "                    \"build an autonomous agent with it!\"\n",
    "                ),\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d6ae4",
   "metadata": {},
   "source": [
    "# 3. Replay the full state history¶\n",
    "Now that you have added steps to the chatbot, you can replay the full state history to see everything that occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "413e3625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e2d0e",
   "metadata": {},
   "source": [
    "## Resume from a checkpoint¶\n",
    "Resume from the to_replay state, which is after the chatbot node in the second graph invocation. Resuming from this point will call the action node next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c2be1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f055800-8988-6008-8006-0a63987bc4c7'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b33b67",
   "metadata": {},
   "source": [
    "# 4. Load a state from a moment-in-time\n",
    "The checkpoint's to_replay.config contains a checkpoint_id timestamp. Providing this checkpoint_id value tells LangGraph's checkpointer to load the state from that moment in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a135e647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like an exciting project! LangGraph's graph-based framework and state machine model make it well-suited for building autonomous agents that can handle complex workflows and decision-making processes. If you need any help with getting started, designing your agent, or troubleshooting along the way, feel free to ask. Good luck with your autonomous agent build!\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
