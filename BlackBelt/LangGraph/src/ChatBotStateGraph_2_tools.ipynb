{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "500caac1",
   "metadata": {},
   "source": [
    "# Add Search Tool as Node in the graph\n",
    "\n",
    "https://app.tavily.com/home\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1909c5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76976ed1",
   "metadata": {},
   "source": [
    "# 1. Install the search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fe8245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-tavily\n",
      "  Downloading langchain_tavily-0.2.4-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.11.14 (from langchain-tavily)\n",
      "  Using cached aiohttp-3.12.13-cp313-cp313-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.20 in /opt/homebrew/lib/python3.13/site-packages (from langchain-tavily) (0.3.26)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /opt/homebrew/lib/python3.13/site-packages (from langchain-tavily) (0.3.66)\n",
      "Collecting mypy<2.0.0,>=1.15.0 (from langchain-tavily)\n",
      "  Downloading mypy-1.16.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /opt/homebrew/lib/python3.13/site-packages (from langchain-tavily) (2.32.4)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.11.14->langchain-tavily)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/homebrew/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/homebrew/lib/python3.13/site-packages (from aiohttp<4.0.0,>=3.11.14->langchain-tavily) (1.18.3)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/homebrew/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /opt/homebrew/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (0.4.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (2.11.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (1.4.23)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/lib/python3.13/site-packages (from langchain<0.4.0,>=0.3.20->langchain-tavily) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/homebrew/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain-tavily) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain-tavily) (3.0.0)\n",
      "Requirement already satisfied: mypy_extensions>=1.0.0 in /opt/homebrew/lib/python3.13/site-packages (from mypy<2.0.0,>=1.15.0->langchain-tavily) (1.1.0)\n",
      "Collecting pathspec>=0.9.0 (from mypy<2.0.0,>=1.15.0->langchain-tavily)\n",
      "  Using cached pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.13/site-packages (from requests<3.0.0,>=2.32.3->langchain-tavily) (2025.1.31)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/homebrew/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.23.0)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain<0.4.0,>=0.3.20->langchain-tavily) (1.3.1)\n",
      "Downloading langchain_tavily-0.2.4-py3-none-any.whl (24 kB)\n",
      "Using cached aiohttp-3.12.13-cp313-cp313-macosx_11_0_arm64.whl (464 kB)\n",
      "Downloading mypy-1.16.1-cp313-cp313-macosx_11_0_arm64.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: pathspec, aiohappyeyeballs, mypy, aiohttp, langchain-tavily\n",
      "\u001b[2K  Attempting uninstall: aiohappyeyeballs\n",
      "\u001b[2K    Found existing installation: aiohappyeyeballs 2.4.6\n",
      "\u001b[2K    Uninstalling aiohappyeyeballs-2.4.6:\n",
      "\u001b[2K      Successfully uninstalled aiohappyeyeballs-2.4.6\n",
      "\u001b[2K  Attempting uninstall: aiohttp0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [mypy]\n",
      "\u001b[2K    Found existing installation: aiohttp 3.11.12━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [mypy]\n",
      "\u001b[2K    Uninstalling aiohttp-3.11.12:m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [mypy]\n",
      "\u001b[2K      Successfully uninstalled aiohttp-3.11.12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [mypy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [langchain-tavily][aiohttp]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "litellm 1.70.0 requires openai<1.76.0,>=1.68.2, but you have openai 1.90.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.13 langchain-tavily-0.2.4 mypy-1.16.1 pathspec-0.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-tavily --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f9fb3d",
   "metadata": {},
   "source": [
    "# 2. Configure your environment\n",
    "Configure your environment with your search engine API key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e698b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"....\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe82135",
   "metadata": {},
   "source": [
    "# 3. Define the tool¶\n",
    "Define the web search tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dfd6cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': \"What's a 'node' in LangGraph?\",\n",
       " 'follow_up_questions': None,\n",
       " 'answer': None,\n",
       " 'images': [],\n",
       " 'results': [{'title': 'Nodes and Edges | langchain-ai/langgraph-101 | DeepWiki',\n",
       "   'url': 'https://deepwiki.com/langchain-ai/langgraph-101/2.2-nodes-and-edges',\n",
       "   'content': 'Nodes and Edges | langchain-ai/langgraph-101 | DeepWiki Nodes and Edges Nodes and Edges What are Nodes and Edges? In LangGraph, a graph is composed of nodes connected by edges to form a directed workflow. Nodes are the workhorses of LangGraph - they are Python functions that receive the current graph state as input, perform operations, and return updates to that state. Edges define the flow of execution between nodes in a LangGraph. graph_builder.add_edge(\"retrieve_documents\", \"generate_response\") Conditional edges use a function to determine the next node based on the current state. Building a Graph with Nodes and Edges graph_builder.add_node(\"retrieve_documents\", retrieve_documents) graph_builder.add_edge(\"retrieve_documents\", \"generate_response\") When designing nodes and edges in LangGraph: Nodes and Edges What are Nodes and Edges? Building a Graph with Nodes and Edges',\n",
       "   'score': 0.8559598,\n",
       "   'raw_content': None},\n",
       "  {'title': 'What is LangGraph? - GeeksforGeeks',\n",
       "   'url': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/',\n",
       "   'content': 'LangGraph is a Python library that helps you build applications like chatbots or AI agents by organizing their logic step-by-step using state machine model. This step configures your Gemini API key and then we create a simple function ask_gemini that takes user input, sends it to the Gemini model and returns the AI-generated response. Creates a state structure with three fields: question, classification and response which flows through the LangGraph. import matplotlib.pyplot as plt from langgraph.graph import StateGraph\\u200bbuilder = StateGraph(GraphState)builder.add_node(\"classify\", classify)builder.add_node(\"respond\", respond)builder.set_entry_point(\"classify\")builder.add_edge(\"classify\", \"respond\")builder.set_finish_point(\"respond\")app = builder.compile()\\u200bdef visualize_workflow(builder): G = nx.DiGraph()\\u200b for node in builder.nodes: G.add_node(node) for edge in builder.edges: G.add_edge(edge[0], edge[1])\\u200b pos = nx.spring_layout(G) nx.draw(G, pos, with_labels=True, node_size=3000, node_color=\"skyblue\", font_size=12, font_weight=\"bold\", arrows=True)  plt.title(\"Langchain Workflow Visualization\") plt.show()\\u200bvisualize_workflow(builder)',\n",
       "   'score': 0.6991933,\n",
       "   'raw_content': None}],\n",
       " 'response_time': 1.49}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e46056",
   "metadata": {},
   "source": [
    "# 4. Define the graph¶\n",
    "For the StateGraph you created in the first tutorial, add bind_tools on the LLM. This lets the LLM know the correct JSON format to use if it wants to use the search engine.\n",
    "\n",
    "Let's first select our LLM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c89515b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain[openai] in /opt/homebrew/lib/python3.13/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /opt/homebrew/lib/python3.13/site-packages (from langchain[openai]) (0.3.66)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /opt/homebrew/lib/python3.13/site-packages (from langchain[openai]) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /opt/homebrew/lib/python3.13/site-packages (from langchain[openai]) (0.4.3)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/homebrew/lib/python3.13/site-packages (from langchain[openai]) (2.11.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/lib/python3.13/site-packages (from langchain[openai]) (1.4.23)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/lib/python3.13/site-packages (from langchain[openai]) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/lib/python3.13/site-packages (from langchain[openai]) (6.0.2)\n",
      "Requirement already satisfied: langchain-openai in /opt/homebrew/lib/python3.13/site-packages (from langchain[openai]) (0.3.25)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /opt/homebrew/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[openai]) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[openai]) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/homebrew/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[openai]) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/homebrew/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[openai]) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain[openai]) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/lib/python3.13/site-packages (from requests<3,>=2->langchain[openai]) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.13/site-packages (from requests<3,>=2->langchain[openai]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.13/site-packages (from requests<3,>=2->langchain[openai]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.13/site-packages (from requests<3,>=2->langchain[openai]) (2025.1.31)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain[openai]) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/homebrew/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain[openai]) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/homebrew/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain[openai]) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/homebrew/lib/python3.13/site-packages (from langsmith>=0.1.17->langchain[openai]) (0.23.0)\n",
      "Requirement already satisfied: anyio in /opt/homebrew/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[openai]) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[openai]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/homebrew/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[openai]) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[openai]) (1.3.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /opt/homebrew/lib/python3.13/site-packages (from langchain-openai->langchain[openai]) (1.90.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/homebrew/lib/python3.13/site-packages (from langchain-openai->langchain[openai]) (0.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (0.9.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/lib/python3.13/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/lib/python3.13/site-packages (from tiktoken<1,>=0.7->langchain-openai->langchain[openai]) (2024.11.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U \"langchain[openai]\" --break-system-packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ea3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"....\"\n",
    "\n",
    "# llm = init_chat_model(\"openai:gpt-4.1\")\n",
    "llm = init_chat_model(\"openai:gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39266f90",
   "metadata": {},
   "source": [
    "### We can now incorporate it into a StateGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68d27fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x115f4d2b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "# highlight-next-line\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fc8172",
   "metadata": {},
   "source": [
    "# 5. Create a function to run the tools\n",
    "Now, create a function to run the tools if they are called. Do this by adding the tools to a new node calledBasicToolNode that checks the most recent message in the state and calls tools if the message contains tool_calls. It relies on the LLM's tool_calling support, which is available in Anthropic, OpenAI, Google Gemini, and a number of other LLM providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2eca286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tools available: {'tavily_search': TavilySearch(max_results=2, api_wrapper=TavilySearchAPIWrapper(tavily_api_key=SecretStr('**********')))}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x115f4d2b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "\n",
    "class BasicToolNode:\n",
    "    \"\"\"A node that runs the tools requested in the last AIMessage.\"\"\"\n",
    "\n",
    "    def __init__(self, tools: list) -> None:\n",
    "        self.tools_by_name = {tool.name: tool for tool in tools}\n",
    "        print(\"Tools available:\", self.tools_by_name)\n",
    "\n",
    "    def __call__(self, inputs: dict):\n",
    "        if messages := inputs.get(\"messages\", []):\n",
    "            message = messages[-1]\n",
    "        else:\n",
    "            raise ValueError(\"No message found in input\")\n",
    "        outputs = []\n",
    "        for tool_call in message.tool_calls:\n",
    "            # print(\"Tool call:\", tool_call)\n",
    "            # if tool_call[\"name\"] not in self.tools_by_name:\n",
    "            #     raise ValueError(\n",
    "            #         f\"Tool '{tool_call['name']}' not found in available tools.\"\n",
    "            #     )\n",
    "            tool_result = self.tools_by_name[tool_call[\"name\"]].invoke(\n",
    "                tool_call[\"args\"]\n",
    "            )\n",
    "            outputs.append(\n",
    "                ToolMessage(\n",
    "                    content=json.dumps(tool_result),\n",
    "                    name=tool_call[\"name\"],\n",
    "                    tool_call_id=tool_call[\"id\"],\n",
    "                )\n",
    "            )\n",
    "        return {\"messages\": outputs}\n",
    "\n",
    "\n",
    "tool_node = BasicToolNode(tools=[tool])\n",
    "# print(\"Tool node created:\", tool_node)\n",
    "graph_builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c16a1",
   "metadata": {},
   "source": [
    "# 6. Define the conditional_edges¶\n",
    "With the tool node added, now you can define the conditional_edges.\n",
    "\n",
    "Edges route the control flow from one node to the next. Conditional edges start from a single node and usually contain \"if\" statements to route to different nodes depending on the current graph state. These functions receive the current graph state and return a string or list of strings indicating which node(s) to call next.\n",
    "\n",
    "Next, define a router function called route_tools that checks for tool_calls in the chatbot's output. Provide this function to the graph by calling add_conditional_edges, which tells the graph that whenever the chatbot node completes to check this function to see where to go next.\n",
    "\n",
    "The condition will route to tools if tool calls are present and END if not. Because the condition can return END, you do not need to explicitly set a finish_point this time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
