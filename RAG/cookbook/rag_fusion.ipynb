{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "993c2768",
   "metadata": {},
   "source": [
    "# RAG Fusion\n",
    "\n",
    "Re-implemented from [this GitHub repo](https://github.com/Raudaschl/rag-fusion), all credit to original author\n",
    "\n",
    "> RAG-Fusion, a search methodology that aims to bridge the gap between traditional search paradigms and the multifaceted dimensions of human queries. Inspired by the capabilities of Retrieval Augmented Generation (RAG), this project goes a step further by employing multiple query generation and Reciprocal Rank Fusion to re-rank search results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcc6791",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "For this example, we will use Pinecone and some fake data. To configure Pinecone, set the following environment variable:\n",
    "\n",
    "- `PINECONE_API_KEY`: Your Pinecone API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661a1c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48ef7e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_documents = {\n",
    "    \"doc1\": \"Climate change and economic impact.\",\n",
    "    \"doc2\": \"Public health concerns due to climate change.\",\n",
    "    \"doc3\": \"Climate change: A social perspective.\",\n",
    "    \"doc4\": \"Technological solutions to climate change.\",\n",
    "    \"doc5\": \"Policy changes needed to combat climate change.\",\n",
    "    \"doc6\": \"Climate change and its impact on biodiversity.\",\n",
    "    \"doc7\": \"Climate change: The science and models.\",\n",
    "    \"doc8\": \"Global warming: A subset of climate change.\",\n",
    "    \"doc9\": \"How climate change affects daily weather.\",\n",
    "    \"doc10\": \"The history of climate change activism.\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde89f0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No active indexes found in your Pinecone project, are you sure you're using the right Pinecone API key and Environment? Please double check your Pinecone dashboard.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m vectorstore = \u001b[43mPineconeVectorStore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_documents\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mOpenAIEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrag-fusion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/langchain_pinecone/vectorstores.py:827\u001b[39m, in \u001b[36mPineconeVectorStore.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, namespace, index_name, upsert_kwargs, pool_threads, embeddings_chunk_size, id_prefix, **kwargs)\u001b[39m\n\u001b[32m    782\u001b[39m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfrom_texts\u001b[39m(\n\u001b[32m    784\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    798\u001b[39m     **kwargs: Any,\n\u001b[32m    799\u001b[39m ) -> PineconeVectorStore:\n\u001b[32m    800\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Construct Pinecone wrapper from raw documents.\u001b[39;00m\n\u001b[32m    801\u001b[39m \n\u001b[32m    802\u001b[39m \u001b[33;03m    This is a user-friendly interface that:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    825\u001b[39m \u001b[33;03m            )\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m     pinecone_index = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_pinecone_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    828\u001b[39m     pinecone = \u001b[38;5;28mcls\u001b[39m(pinecone_index, embedding, text_key, namespace, **kwargs)\n\u001b[32m    830\u001b[39m     pinecone.add_texts(\n\u001b[32m    831\u001b[39m         texts,\n\u001b[32m    832\u001b[39m         metadatas=metadatas,\n\u001b[32m   (...)\u001b[39m\u001b[32m    838\u001b[39m         **(upsert_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}),\n\u001b[32m    839\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/lib/python3.13/site-packages/langchain_pinecone/vectorstores.py:770\u001b[39m, in \u001b[36mPineconeVectorStore.get_pinecone_index\u001b[39m\u001b[34m(cls, index_name, pool_threads, pinecone_api_key)\u001b[39m\n\u001b[32m    768\u001b[39m     index = client.Index(index_name)\n\u001b[32m    769\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(index_names) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    771\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo active indexes found in your Pinecone project, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    772\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mare you sure you\u001b[39m\u001b[33m'\u001b[39m\u001b[33mre using the right Pinecone API key and Environment? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    773\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease double check your Pinecone dashboard.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    776\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    777\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIndex \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m not found in your Pinecone project. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    778\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDid you mean one of the following indexes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m.join(index_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    779\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: No active indexes found in your Pinecone project, are you sure you're using the right Pinecone API key and Environment? Please double check your Pinecone dashboard."
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import LlamaCppEmbeddings\n",
    "\n",
    "# vectorstore = PineconeVectorStore.from_texts(\n",
    "#     list(all_documents.values()), OpenAIEmbeddings(), index_name=\"rag-fusion\"\n",
    "# )\n",
    "\n",
    "vectorstore = PineconeVectorStore.from_texts(\n",
    "    list(all_documents.values()), LlamaCppEmbeddings(model=\"llama-text-embed-v2\"), index_name=\"rag-fusion\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ddd041",
   "metadata": {},
   "source": [
    "## Define the Query Generator\n",
    "\n",
    "We will now define a chain to do the query generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d547524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "af9ab4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"langchain-ai/rag-fusion-query-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3628b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", \"You are a helpful assistant that generates multiple search queries based on a single input query.\"),\n",
    "#     (\"user\", \"Generate multiple search queries related to: {original_query}\"),\n",
    "#     (\"user\", \"OUTPUT (4 queries):\")\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d6cbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_queries = (\n",
    "    prompt | ChatOpenAI(temperature=0) | StrOutputParser() | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2824cd",
   "metadata": {},
   "source": [
    "## Define the full chain\n",
    "\n",
    "We can now put it all together and define the full chain. This chain:\n",
    "    \n",
    "    1. Generates a bunch of queries\n",
    "    2. Looks up each query in the retriever\n",
    "    3. Joins all the results together using reciprocal rank fusion\n",
    "    \n",
    "    \n",
    "Note that it does NOT do a final generation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ca0bfec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query = \"impact of climate change\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "02437d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore.from_existing_index(\"rag-fusion\", OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "46a9a0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.load import dumps, loads\n",
    "\n",
    "\n",
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    fused_scores = {}\n",
    "    for docs in results:\n",
    "        # Assumes the docs are returned in sorted order of relevance\n",
    "        for rank, doc in enumerate(docs):\n",
    "            doc_str = dumps(doc)\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "    return reranked_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3f9d4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = generate_queries | retriever.map() | reciprocal_rank_fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d70c4fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(page_content='Climate change and economic impact.'),\n",
       "  0.06558258417063283),\n",
       " (Document(page_content='Climate change: A social perspective.'),\n",
       "  0.06400409626216078),\n",
       " (Document(page_content='How climate change affects daily weather.'),\n",
       "  0.04787506400409626),\n",
       " (Document(page_content='Climate change and its impact on biodiversity.'),\n",
       "  0.03306010928961749),\n",
       " (Document(page_content='Public health concerns due to climate change.'),\n",
       "  0.016666666666666666),\n",
       " (Document(page_content='Technological solutions to climate change.'),\n",
       "  0.016666666666666666),\n",
       " (Document(page_content='Policy changes needed to combat climate change.'),\n",
       "  0.01639344262295082)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"original_query\": original_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7866e551",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
